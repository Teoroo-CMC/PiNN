<!--
  This Basic theme serves as an example for how to create other
  themes by demonstrating the features with minimal HTML and CSS.
  Comments like this will be through the code to explain briefly
  what each feature is and point you to the MkDocs documentation
  to find out more.
-->
<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <!--
    The page_title contains the title for a page as shown in the navigation.
    Site name contains the name as defined in the mkdocs.yml
  -->
  <title>Layer Debug - PiNN</title>

  <link rel="stylesheet" href="../../css/theme.css">
  <link rel="stylesheet" href="../../css/notebook.css">
  <link rel="stylesheet" href="../../css/pygments.css">
  <link rel="icon" href="data:,">
  
    <link href="../../assets/_mkdocstrings.css" rel="stylesheet">
  
    <link href="../../css/extra.css" rel="stylesheet">
  
    <link href="../../css/ansi-colours.css" rel="stylesheet">
  
    <link href="../../css/jupyter-cells.css" rel="stylesheet">
  
    <link href="../../css/pandas-dataframe.css" rel="stylesheet">
  

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,600;1,400;1,700&family=Noto+Sans:ital,wght@0,400;0,600;1,400;1,600&display=swap" rel="stylesheet">
  <script
  src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
  integrity="sha256-3edrmyuQ0w65f8gfBsqowzjJe2iM6n0nKciPUp8y+7E="
  crossorigin="anonymous"></script>

  <script>
    var base_url = "../..";
    $(document).ready(function(){
          $('table').wrap('<div class="table-wrapper"></div>');
    });
  </script>

  <script src="../../js/mike.js"></script>

  
    <script src="../../js/mathjax.js"></script>
  
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  
    <script src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.3/tex-chtml-nofont.js"></script>
  

</head>

<body>
  <header class="header">
    <ul>
      <li id="logo">
        <a href="../.."><span>Pi</span>NN</a>
      </li>
      
      
  
  <li  class="tab" >
    <a href="../..">
      Home
    </a>
  </li>

      
      
  
  <li  class="tab" >
    <a href="../../usage/overview/">
      Usage
    </a>
  </li>

      
      
  
  <li class="active tab" >
    <a href="../overview/">
      Notebooks
    </a>
  </li>

      
      <li class="tools">
        
          <a id="nav-toggle" class="tool" onclick="nav_toggle()">
        
          <svg><use xlink:href="../../svg/sprite.svg#menu-2"></use></svg>
        </a>
        <script>
           function nav_toggle() {
               var bar = document.getElementById("tab-bar");
               if (bar.style.display === "none") {
                   bar.style.display = "block";
               } else {
                   bar.style.display = "none";
               }
           }
          function nav_reset() {
              var bar = document.getElementById("tab-bar");
              if (window.innerWidth>950){
                  bar.style.display = "block";
              } else {
                  bar.style.display = "none";
              }
          }
          window.onresize = nav_reset;
        </script>
        
        <a class="tool">
          <svg><use xlink:href="../../svg/sprite.svg#tag"></use></svg>
          <div class="version"></div>
        </a>
        
        
        <a class="tool" href="https://github.com/teoroo-cmc/pinn/">
          <svg><use xlink:href="../../svg/sprite.svg#brand-github"></use></svg>
          <span>teoroo-cmc/pinn</span>
        </a>
        
      </li>
    </ul>
  </header>


  <div id="main">
    <div id="tab-bar">
      <ul>
      
       
  
  <li  class="tab" >
    <a href="../..">
      Home
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
             </ul>
           </div>
         
      
       
  
  <li  class="tab" >
    <a href="../../usage/overview/">
      Usage
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
             </ul>
           </div>
         
      
       
  
  <li class="active tab" >
    <a href="../overview/">
      Notebooks
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
                 
                   
    <li >
      <a href="../overview/" class="">
        Overview
      </a>
    </li>

                 
                   
  <a class="nav-title" > Tutorials </a>
  
    
    <li >
      <a href="../Quick_tour/" class="">
        Quick Start
      </a>
    </li>

  
    
    <li >
      <a href="../More_on_training/" class="">
        Training Tips
      </a>
    </li>

  

                 
                   
  <a class="nav-title" > Examples </a>
  
    
    <li >
      <a href="../Customizing_dataset/" class="">
        Custom Data
      </a>
    </li>

  
    
    <li >
      <a href="../Learn_LJ_potential/" class="">
        LJ Potential
      </a>
    </li>

  

                 
                   
  <a class="nav-title" > Develop </a>
  
    
    <li class="active">
      <a href="./" class="">
        Layer Debug
      </a>
    </li>

  

                 
               
             </ul>
           </div>
         
      
      </ul>
    </div>

    <div id="content">
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script>
(function() {
  function addWidgetsRenderer() {
    var requireJsScript = document.createElement('script');
    requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';

    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var jupyterWidgetsScript = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    jupyterWidgetsScript.src = widgetRendererSrc;

    document.body.appendChild(requireJsScript);
    document.body.appendChild(jupyterWidgetsScript);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="debugging-pinn-layers-and-networks">Debugging PiNN layers and networks <a href="https://colab.research.google.com/github/Teoroo-CMC/PiNN/blob/master/docs/notebooks/Layer_debug.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Teoroo</span><span class="o">-</span><span class="n">CMC</span><span class="o">/</span><span class="n">PiNN</span>
<span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">nv</span> <span class="o">-</span><span class="n">nc</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Teoroo</span><span class="o">-</span><span class="n">CMC</span><span class="o">/</span><span class="n">PiNN_lab</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">resources</span><span class="o">/</span><span class="n">qm9_train</span><span class="o">.</span><span class="p">{</span><span class="n">yml</span><span class="p">,</span><span class="n">tfr</span><span class="p">}</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="loading-data">Loading data</h2>
<p>For the purpose of testing we download a subset of the QM9 dataset used in <a href="https://github.com/Teoroo-CMC/PiNN_lab">PiNN_lab</a>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pinn.io</span> <span class="kn">import</span> <span class="n">load_tfrecord</span><span class="p">,</span> <span class="n">sparse_batch</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_tfrecord</span><span class="p">(</span><span class="s2">&quot;qm9_train.yml&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">datum</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">datum</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
    <span class="k">break</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>{'A': TensorShape([10]), 'B': TensorShape([10]), 'C': TensorShape([10]), 'Cv': TensorShape([10]), 'G': TensorShape([10]), 'H': TensorShape([10]), 'U': TensorShape([10]), 'U0': TensorShape([10]), 'alpha': TensorShape([10]), 'coord': TensorShape([176, 3]), 'elems': TensorShape([176]), 'gap': TensorShape([10]), 'homo': TensorShape([10]), 'lumo': TensorShape([10]), 'mu': TensorShape([10]), 'r2': TensorShape([10]), 'zpve': TensorShape([10]), 'ind_1': TensorShape([176, 1])}
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="using-pinn-layers">Using PiNN Layers</h2>
<p>PiNN networks and layers are Keras <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer">Layers</a> 
and <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">Models</a>. </p>
<p>To use them, you create an instance of layer, after that, the layer object can be used as a function. Each layer
is initialized with different parameters and requires different input tensors, see their individual documentation
for the details.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pinn.layers</span> <span class="kn">import</span> <span class="n">CellListNL</span>
<span class="kn">from</span> <span class="nn">pinn.networks.pinet</span> <span class="kn">import</span> <span class="n">PILayer</span><span class="p">,</span> <span class="n">PiNet</span>

<span class="n">nl</span> <span class="o">=</span> <span class="n">CellListNL</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="k">for</span> <span class="n">datum</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">nl</span><span class="p">(</span><span class="n">datum</span><span class="p">)</span>
    <span class="k">break</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The definition of a layer needs three parts:</p>
<ul>
<li><code>__init__</code> defines the layer object; </li>
<li><code>build</code> creates the necessary variables or sub-layers; </li>
<li><code>call</code> defines how the input tensors are processed.</li>
</ul>
<p>The <code>build()</code> method is only called once when the layer is used for the first tiem (e.g. in a loop).
See below for an example definition for the <code>PILayer</code></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="err">??</span><span class="n">PILayer</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea">
<pre>
<code><span class="ansi-red-fg">Init signature:</span> PILayer<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Source:</span>        
<span class="ansi-green-fg">class</span> PILayer<span class="ansi-blue-fg">(</span>tf<span class="ansi-blue-fg">.</span>keras<span class="ansi-blue-fg">.</span>layers<span class="ansi-blue-fg">.</span>Layer<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">"""PiNN style interaction layer</span>

<span class="ansi-blue-fg">    Args:</span>
<span class="ansi-blue-fg">        n_nodes: number of nodes to use</span>
<span class="ansi-blue-fg">            Note that the last element of n_nodes specifies the dimention of</span>
<span class="ansi-blue-fg">            the fully connected network before applying the basis function.</span>
<span class="ansi-blue-fg">            Dimension of the last node is [pairs*n_nodes[-1]*n_basis], the</span>
<span class="ansi-blue-fg">            output is then summed with the basis to form the interaction nodes</span>
<span class="ansi-blue-fg">        **kwargs: keyword arguments will be parsed to the feed forward layers</span>
<span class="ansi-blue-fg">    """</span>
    <span class="ansi-green-fg">def</span> __init__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> n_nodes<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">64</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        super<span class="ansi-blue-fg">(</span>PILayer<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__init__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>n_nodes <span class="ansi-blue-fg">=</span> n_nodes
        self<span class="ansi-blue-fg">.</span>kwargs <span class="ansi-blue-fg">=</span> kwargs

    <span class="ansi-green-fg">def</span> build<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> shapes<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        self<span class="ansi-blue-fg">.</span>n_basis <span class="ansi-blue-fg">=</span> shapes<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span>
        n_nodes_iter <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>n_nodes<span class="ansi-blue-fg">.</span>copy<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
        n_nodes_iter<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">*=</span> self<span class="ansi-blue-fg">.</span>n_basis
        self<span class="ansi-blue-fg">.</span>ff_layer <span class="ansi-blue-fg">=</span> FFLayer<span class="ansi-blue-fg">(</span>n_nodes_iter<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>self<span class="ansi-blue-fg">.</span>kwargs<span class="ansi-blue-fg">)</span>

    <span class="ansi-green-fg">def</span> call<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> tensors<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        ind_2<span class="ansi-blue-fg">,</span> prop<span class="ansi-blue-fg">,</span> basis <span class="ansi-blue-fg">=</span> tensors
        ind_i <span class="ansi-blue-fg">=</span> ind_2<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span>
        ind_j <span class="ansi-blue-fg">=</span> ind_2<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span>
        prop_i <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>gather<span class="ansi-blue-fg">(</span>prop<span class="ansi-blue-fg">,</span> ind_i<span class="ansi-blue-fg">)</span>
        prop_j <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>gather<span class="ansi-blue-fg">(</span>prop<span class="ansi-blue-fg">,</span> ind_j<span class="ansi-blue-fg">)</span>

        inter <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>concat<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>prop_i<span class="ansi-blue-fg">,</span> prop_j<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> axis<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
        inter <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>ff_layer<span class="ansi-blue-fg">(</span>inter<span class="ansi-blue-fg">)</span>
        inter <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>reshape<span class="ansi-blue-fg">(</span>inter<span class="ansi-blue-fg">,</span> tf<span class="ansi-blue-fg">.</span>concat<span class="ansi-blue-fg">(</span>
            <span class="ansi-blue-fg">[</span>tf<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">(</span>inter<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>n_nodes<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>n_basis<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
        inter <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>reduce_sum<span class="ansi-blue-fg">(</span>inter<span class="ansi-blue-fg">*</span>basis<span class="ansi-blue-fg">,</span> axis<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
        <span class="ansi-green-fg">return</span> inter
<span class="ansi-red-fg">File:</span>           ~/code/PiNN/pinn/networks/pinet.py
<span class="ansi-red-fg">Type:</span>           type
<span class="ansi-red-fg">Subclasses:</span>     
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="using-pinn-networks">Using PiNN Networks</h2>
<p><code>network</code> (Keras Models) are defined similarly, but they can be directly used to perform regression task.</p>
<p>By default, <code>network</code>  produces per-atom predictions, this can be changed by the <code>out_pool</code> parameter to 
get some simple per-structure predictions. In that case, the network object can be used to perform trainig directly.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">label_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># defines the label to train on</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;lumo&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_data</span><span class="p">)</span>
<span class="n">pinet</span> <span class="o">=</span> <span class="n">PiNet</span><span class="p">(</span><span class="n">out_pool</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">)</span>
<span class="n">pinet</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
<span class="n">pinet</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Epoch 1/3
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>/home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("Adam/gradients/concat_1:0", shape=(None,), dtype=int32), values=Tensor("Adam/gradients/concat:0", shape=(None, 16), dtype=float32), dense_shape=Tensor("gradient_tape/pi_net_1/gc_block_7/pi_layer_7/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("Adam/gradients/concat_3:0", shape=(None,), dtype=int32), values=Tensor("Adam/gradients/concat_2:0", shape=(None, 16), dtype=float32), dense_shape=Tensor("gradient_tape/pi_net_1/gc_block_6/pi_layer_6/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
/home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor("Adam/gradients/concat_5:0", shape=(None,), dtype=int32), values=Tensor("Adam/gradients/concat_4:0", shape=(None, 16), dtype=float32), dense_shape=Tensor("gradient_tape/pi_net_1/gc_block_5/pi_layer_5/Cast:0", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  warnings.warn(
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>2000/2000 [==============================] - 37s 17ms/step - loss: 0.0551
Epoch 2/3
2000/2000 [==============================] - 35s 18ms/step - loss: 0.0285
Epoch 3/3
2000/2000 [==============================] - 35s 17ms/step - loss: 0.0240
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>&lt;keras.callbacks.History at 0x7f17c86591f0&gt;</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="further-benchmarks">Further benchmarks</h2>
<p>For more advanced usage you are recommended to use the <code>Model</code> API to define the trainig loss, derived predicates.
For traininig potential energy surfaces, you are recommended to use <code>pinn.models.potential_model</code> in combination with the command line interface (CLI).</p>
<p>Alternatively, see the <a href="../More_on_training/">Trainig Tips</a> notebook to see how to run the tranining interactively in a notebook.</p>
</div>
</div>
</div>
    </div>

  </div>

  <div class="page">
    <div class="page-prev">
      
      <a href="../Learn_LJ_potential/" title="LJ Potential"><span>«</span> Previous</a>
      
    </div>
    <div class="page-next">
      
    </div>
  </div>

  <div class="footer">
    Built with <a href="https://www.mkdocs.org">mkdocs</a> and the <a href="https://github.com/yqshao/mkdocs-flux-theme">flux</a> theme.
  </div>
</body>
</html>