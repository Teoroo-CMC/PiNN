<!--
  This Basic theme serves as an example for how to create other
  themes by demonstrating the features with minimal HTML and CSS.
  Comments like this will be through the code to explain briefly
  what each feature is and point you to the MkDocs documentation
  to find out more.
-->
<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <!--
    The page_title contains the title for a page as shown in the navigation.
    Site name contains the name as defined in the mkdocs.yml
  -->
  <title>Training Tips - PiNN</title>

  <link rel="stylesheet" href="../../css/theme.css">
  <link rel="stylesheet" href="../../css/notebook.css">
  <link rel="stylesheet" href="../../css/pygments.css">
  <link rel="icon" href="data:,">
  
    <link href="../../assets/_mkdocstrings.css" rel="stylesheet">
  
    <link href="../../css/extra.css" rel="stylesheet">
  
    <link href="../../css/ansi-colours.css" rel="stylesheet">
  
    <link href="../../css/jupyter-cells.css" rel="stylesheet">
  
    <link href="../../css/pandas-dataframe.css" rel="stylesheet">
  

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,600;1,400;1,700&family=Noto+Sans:ital,wght@0,400;0,600;1,400;1,600&display=swap" rel="stylesheet">
  <script
  src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
  integrity="sha256-3edrmyuQ0w65f8gfBsqowzjJe2iM6n0nKciPUp8y+7E="
  crossorigin="anonymous"></script>

  <script>
    var base_url = "../..";
    $(document).ready(function(){
          $('table').wrap('<div class="table-wrapper"></div>');
    });
  </script>

  <script src="../../js/mike.js"></script>

  
    <script src="../../js/mathjax.js"></script>
  
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  
    <script src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.3/tex-chtml-nofont.js"></script>
  

</head>

<body>
  <header class="header">
    <ul>
      <li id="logo">
        <a href="../.."><span>Pi</span>NN</a>
      </li>
      
      
  
  <li  class="tab" >
    <a href="../..">
      Home
    </a>
  </li>

      
      
  
  <li  class="tab" >
    <a href="../../usage/overview/">
      Usage
    </a>
  </li>

      
      
  
  <li class="active tab" >
    <a href="../overview/">
      Notebooks
    </a>
  </li>

      
      <li class="tools">
        
          <a id="nav-toggle" class="tool" onclick="nav_toggle()">
        
          <svg><use xlink:href="../../svg/sprite.svg#menu-2"></use></svg>
        </a>
        <script>
           function nav_toggle() {
               var bar = document.getElementById("tab-bar");
               if (bar.style.display === "none") {
                   bar.style.display = "block";
               } else {
                   bar.style.display = "none";
               }
           }
          function nav_reset() {
              var bar = document.getElementById("tab-bar");
              if (window.innerWidth>950){
                  bar.style.display = "block";
              } else {
                  bar.style.display = "none";
              }
          }
          window.onresize = nav_reset;
        </script>
        
        <a class="tool">
          <svg><use xlink:href="../../svg/sprite.svg#tag"></use></svg>
          <div class="version"></div>
        </a>
        
        
        <a class="tool" href="https://github.com/teoroo-cmc/pinn/">
          <svg><use xlink:href="../../svg/sprite.svg#brand-github"></use></svg>
          <span>teoroo-cmc/pinn</span>
        </a>
        
      </li>
    </ul>
  </header>


  <div id="main">
    <div id="tab-bar">
      <ul>
      
       
  
  <li  class="tab" >
    <a href="../..">
      Home
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
             </ul>
           </div>
         
      
       
  
  <li  class="tab" >
    <a href="../../usage/overview/">
      Usage
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
             </ul>
           </div>
         
      
       
  
  <li class="active tab" >
    <a href="../overview/">
      Notebooks
    </a>
  </li>

         
           <div class="nav-bar">
             <ul>
               
                 
                   
    <li >
      <a href="../overview/" class="">
        Overview
      </a>
    </li>

                 
                   
  <a class="nav-title" > Tutorials </a>
  
    
    <li >
      <a href="../Quick_tour/" class="">
        Quick Start
      </a>
    </li>

  
    
    <li class="active">
      <a href="./" class="">
        Training Tips
      </a>
    </li>

  

                 
                   
  <a class="nav-title" > Examples </a>
  
    
    <li >
      <a href="../Customizing_dataset/" class="">
        Custom Data
      </a>
    </li>

  
    
    <li >
      <a href="../Learn_LJ_potential/" class="">
        LJ Potential
      </a>
    </li>

  

                 
                   
  <a class="nav-title" > Develop </a>
  
    
    <li >
      <a href="../Layer_debug/" class="">
        Layer Debug
      </a>
    </li>

  

                 
               
             </ul>
           </div>
         
      
      </ul>
    </div>

    <div id="content">
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script>
(function() {
  function addWidgetsRenderer() {
    var requireJsScript = document.createElement('script');
    requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';

    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var jupyterWidgetsScript = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    jupyterWidgetsScript.src = widgetRendererSrc;

    document.body.appendChild(requireJsScript);
    document.body.appendChild(jupyterWidgetsScript);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="optimizing-the-training">Optimizing the training <a href="https://colab.research.google.com/github/Teoroo-CMC/PiNN/blob/master/docs/notebooks/More_on_training.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></h1>
<p>This notebooks covers more details on tweaking and optimizing the training process.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Install PiNN &amp;amp; download QM9 dataset</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Teoroo</span><span class="o">-</span><span class="n">CMC</span><span class="o">/</span><span class="n">PiNN</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">dsgdb9nsd</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">curl</span> <span class="o">-</span><span class="n">sSL</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ndownloader</span><span class="o">.</span><span class="n">figshare</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">files</span><span class="o">/</span><span class="mi">3195389</span> <span class="o">|</span> <span class="n">tar</span> <span class="n">xj</span> <span class="o">-</span><span class="n">C</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">dsgdb9nsd</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">from</span> <span class="nn">pinn.io</span> <span class="kn">import</span> <span class="n">load_qm9</span><span class="p">,</span> <span class="n">sparse_batch</span>
<span class="kn">from</span> <span class="nn">pinn.networks.pinet</span> <span class="kn">import</span> <span class="n">PiNet</span>
<span class="kn">from</span> <span class="nn">pinn.utils</span> <span class="kn">import</span> <span class="n">get_atomic_dress</span>
<span class="kn">from</span> <span class="nn">pinn</span> <span class="kn">import</span> <span class="n">get_model</span><span class="p">,</span> <span class="n">get_network</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">index_warning</span> <span class="o">=</span> <span class="s1">&#39;Converting sparse IndexedSlices&#39;</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">index_warning</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="optimizing-the-pipeline">Optimizing the pipeline</h2>
<h3 id="caching">Caching</h3>
<p>Caching stores the decoded dataset in the memory.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># For the purpose of testing, we use only 1000 samples from QM9</span>
<span class="n">filelist</span> <span class="o">=</span> <span class="n">glob</span><span class="p">(</span><span class="s1">&#39;/tmp/dsgdb9nsd/*.xyz&#39;</span><span class="p">)[:</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">load_qm9</span><span class="p">(</span><span class="n">filelist</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="c1"># &quot;Warm up&quot; the graph</span>
<span class="o">%</span><span class="n">timeit</span> <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>51.5 ms ± 3.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This speed indicates the IO limit of our current setting.</p>
<p>Now let's cache the dataset to the memory.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="c1"># &quot;Warm up&quot; the graph</span>
<span class="o">%</span><span class="n">timeit</span> <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>385 µs ± 35.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="preprocessing">Preprocessing</h3>
<p>You might also see a notable difference in the performance with and without preprocessing. This is especially helpful when you are training with GPUs.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">pinet</span> <span class="o">=</span> <span class="n">PiNet</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">pinet</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span> <span class="c1"># &quot;Warm up&quot; the graph</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">pinet</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>89 ms ± 4.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">pinet</span> <span class="o">=</span> <span class="n">PiNet</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">pinet</span><span class="o">.</span><span class="n">preprocess</span><span class="p">)</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="c1"># &quot;Warm up&quot; the graph</span>
<span class="o">%</span><span class="n">timeit</span> <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>WARNING:tensorflow:From /home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
545 µs ± 38.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can even cache the preprocessed data.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">pinet</span> <span class="o">=</span> <span class="n">PiNet</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">pinet</span><span class="o">.</span><span class="n">preprocess</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="c1"># &quot;Warm up&quot; the graph</span>
<span class="o">%</span><span class="n">timeit</span> <span class="nb">next</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>289 µs ± 2.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="atomic-dress">Atomic dress</h2>
<p>Scaling and aligning the labels can 
enhance the performance of the models, and avoid numerical instability.
For datasets like QM9, we can assign an atomic energy to each atom according
to their elements to approximate the total energy. This can be done by a simple 
linear regression. We provide a simple tool to generate such "atomic dresses".</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">filelist</span> <span class="o">=</span> <span class="n">glob</span><span class="p">(</span><span class="s1">&#39;/tmp/dsgdb9nsd/*.xyz&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">load_qm9</span><span class="p">(</span><span class="n">filelist</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>
<span class="n">dress</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> <span class="n">get_atomic_dress</span><span class="p">(</span><span class="n">dataset</span><span class="p">()[</span><span class="s1">&#39;train&#39;</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Applying the atomic dress converts the QM9 energies to a "normal" distribution.
It also gives us some ideas about the relative distribution of energies, and 
how much our neural network improves from the naive guess of the atomic dress.</p>
<p>After applying the atomic dress, it turns out that the distribution of our training set is only about 0.05 Hartree, or 30 kcal/mol.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">error</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
<span class="n">dress</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>{1: -0.6037799981310462,
 6: -38.07402501506576,
 7: -54.74923962293649,
 8: -75.2255233345936,
 9: -99.86678682702703}</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_png output_subarea">
<img alt="No description has been provided for this image" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXoAAAD0CAYAAACVbe2MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWF0lEQVR4nO3df5Bd5XnY8e/Dj4ASa2eE2S12GVANIiYuY2iWMiqhWAMxNYImofkxNCLMWGGThtBQEAaTWCExKMKIOqnbDlbDdOwomYSEZEysFjC2AlgjDIuD7bpKHTAiNrHQEhArYhkj8fSP8664u9yrvSvdu7t69f3M7Oie57zvvc9ZrR69+573nBOZiSSpXkfMdQKSpP6y0EtS5Sz0klQ5C70kVc5CL0mVs9BLUuWOmusEpjr++ONz8eLFc52GJB1SnnzyyRczc7DdvnlX6BcvXszo6OhcpyFJh5SIeK7TPqduJKlyFnpJqpyFXpIqZ6GXpMpZ6CWpcl2tuomIG4DFwIvAEmAlsABYC3yzxG7OzBda2g8Ai4AHM/O+Ej8TuBp4FhgCVmXmnt4djiRpqmkLfUScAHwYOD4z34iIzwCXAecBD2XmPRFxKbAOuCIizgGWZebFEXEUsDUiHgbGgQ3AhZm5PSLuBK4E7u7PoUmSoLupm+8C36cZoQO8Dfg6sBzYUmKbyzbAJRPxMlrfCpwPvAtYkJnb2/SRJPXJtCP6zBwvUzF/EhHfAb4NPE0z9bKrNBsHFpUR/BBNcadl3xAw1tK+NT7J2NgYw8PD+7ZHRkYYGRmZyTFJ1Vl808a28W1rHStpet1M3ZwJ3AD8i8zcU6ZcVgM7gIXATprR/stl/0R8wkBp2yk+yeDgoFfGSlIPdTN180+Bl1pOmn4HOBbYCCwtsXPLNq3xiDgaOB14hOak7e4y5z+1jySpT7pZdXM/cHEZye8E/jlwLfAacHtEnAacAqwCyMzHImJTRKyhWXVzfWbuBIiIFcBt5Z4MRwKf6unRSIe4TlM00sHoZo5+L82SyHau6tDnjg7xp2iWZkqSZokXTElS5Sz0klQ5C70kVc5CL0mVm3dPmJLUPS+kUjcc0UtS5Sz0klQ5C70kVc5CL0mVs9BLUuVcdSPNAe9po9nkiF6SKmehl6TKWeglqXIWekmqnCdjpQp5awS1ckQvSZWz0EtS5aaduomIxcDngW+V0ADwVeA6YC3NQ7+XADdn5gulzw2l3SLgwcy8r8TPpHks4bPAELCq5aHjkqQ+6GaOfhfwS5n5EEBE3AI8BKwBHsrMeyLiUmAdcEVEnAMsy8yLI+IoYGtEPAyMAxuACzNze3nY+JXA3T0/Kmme8MIozQfTTt1k5j+0FPljgOHM/CKwHNhSmm0u2wCXTMTLaH0rcD7wLmBBZm5v00eS1CcznaO/HPjj8nqIZrQPzWh9URnBt8Yn9g3tJz7J2NgYw8PD+77Wr18/wxQlSa1murzyZ4CfLK93AAuBnTTz8S9n5p6ImIhPGChtO8UnGRwcZHR0dIZpSZI66XpEHxHvA7Zk5usltBFYWl6fW7YnxSPiaOB04BGak7a7I+KENn0kSX0ykxH9LwHXtGzfDNweEacBpwCrADLzsYjYFBFraFbdXJ+ZOwEiYgVwW0Q8BxwJfOrgD0GStD9dF/rMvHzK9kvAVR3a3tEh/hSwcgb5SZIOkhdMSVLlLPSSVDkLvSRVzkIvSZWz0EtS5Sz0klQ5HzwiHUb2d5M1H0pSL0f0klQ5C70kVc5CL0mVs9BLUuU8GSv1gE+S0nzmiF6SKmehl6TKWeglqXIWekmqnIVekipnoZekynW1vDIifhi4HNgNnA/cAuwAPgI8DSymeTbsqxFxBLAG2FXid2fmY+V9LgQuK30zM3+rh8ciSWpj2kIfEUcC/xm4NDPfiIhPA3uAPwBWZ+bjEXENcCNN4f9ZYCAzb4qI44DHIuJ04BjgLuA9mflaRNwbERdk5uf7dGySJLqbujkbCOCaiPgwcCmwE1gGPFHabAYmbn23HNgC+x4g/j3gPcBS4LnMfK1NH0lSn3QzdXMyTZG+PDNfiYgNwNuB3ZmZpc04MFReD9FM2zBl32CH+CRjY2MMDw/v2x4ZGWFkZKS7o5EkvUU3hX4c+JvMfKVsfxE4D1gQEVGK/QDNvDvlz4Ut/Sf2ZYf4JIODg4yOjs7oICRJnXUzdfMl4O1lrh6aEf7XgU000zoA5wITN/vYSPMbAGWO/tjSfgtwckQc06aPJKlPph3RZ+ZLEXEj8LsRMUYzBfPbwB8BqyPi/cBJwHWlyz3AWRHxmyX+C5m5F/huRPwH4L+U9/mqJ2Ilqf+6Wl6ZmX8B/MWU8Dbgg23avkGzAqfd+3wO+NzMUpQkHQwvmJKkylnoJalyFnpJqpyFXpIq56MEJQGdH4e4ba0XsB/qHNFLUuUs9JJUOQu9JFXOQi9JlfNkrDQDnU5YSvOZI3pJqpyFXpIqZ6GXpMpZ6CWpchZ6SaqchV6SKmehl6TKWeglqXJdXTAVEY8B3yubezPzgvLg77XAN4ElwM2Z+UJpfwMwACwCHszM+0r8TOBq4FlgCFiVmXt6dziSpKm6vTL2/sy8ZUpsDfBQZt4TEZcC64ArIuIcYFlmXhwRRwFbI+JhYBzYAFyYmdsj4k7gSuDunhyJJKmtbqduzoiIGyPiloiYuDn1cmBLeb25bANcMhEvo/WtwPnAu4AFmbm9TR9JUp90O6K/PTMfj4gjgUciYhfN1Muusn8cWFRG8EM0xZ2WfUPAWEv71vgkY2NjDA8P79seGRlhZGSkyzQlSVN1Vegz8/Hy596IeBRYBuwAFgI7aebjX87MPRExEZ8wUNp2ik8yODjI6OjozI9EktTWtFM3EfHuiFjZEloCPANsBJaW2Lllm9Z4RBwNnA48QnPSdndEnNCmjySpT7oZ0Y8DyyPinTSj8G8BfwT8L+D2iDgNOAVYBZCZj0XEpohYQ7Pq5vrM3AkQESuA2yLiOeBI4FM9Ph5J0hTTFvrM/Hvgsja7XgKu6tDnjg7xp4CV7fZJ84n3nVdNvGBKkipnoZekylnoJalyFnpJqpyFXpIqZ6GXpMpZ6CWpchZ6SaqchV6SKtft3SslHaY6XSW8ba13GT9UOKKXpMpZ6CWpchZ6SaqchV6SKmehl6TKWeglqXIWekmqnIVekirX9QVTEbEA+BLwYGauiohjgXXA8zQPDF+bmd8obVcAZwF7gWcy85Mlvhj4CPA0sJjmebKv9uxoJElvMZMrY28F/rpl+1rg7zLzYxFxBnA3cF5EnEjzoPCzMjMj4omI+EJm/i1wF7A6Mx+PiGuAG2kKvySpT7qauomIK4DNwLMt4eXAFoDM/Brw3ogYAC4CnszMLO22AB+IiKOBZcATJb65vIckqY+mLfQR8SPA6Zn551N2DQG7WrbHS6xT/Hhgd8t/ABPxScbGxhgeHt73tX79+q4PRpL0Vt1M3fwU8L2IuAn4MeAHIuJaYAewsKXdQIntAE6dEn8aeBFYEBFRiv1E+0kGBwcZHR09gEORJLUzbaHPzNsmXpcTsG/LzN8tr5cCj5Y5+q9k5nhEPABc01LQlwKfyMzXI2ITcDbwOHAu0P62eJKknpnJqpt/B/xrmhH95cDvAesi4jdoRvArATLz2xGxDvh4ROwFfr+ciAX4ZWB1RLwfOAm4rneHIklqp+tCn5n3AvdOCV/doe0GYEOb+DbggzPIT5J0kHzwiA5rnR6qIdXEK2MlqXIWekmqnIVekipnoZekynkyVtIB6XQie9ta72wy3ziil6TKWeglqXIWekmqnIVekipnoZekylnoJalyFnpJqpyFXpIqZ6GXpMpZ6CWpchZ6SaqchV6SKjftTc0i4gjgL4EvAT8AnELzOMAFwFrgm8AS4ObMfKH0uQEYABYBD2bmfSV+Js3jB58FhoBVmbmnt4ckTeZTpHS46/bulVsy81aAiPgMcBlwHvBQZt4TEZcC64ArIuIcYFlmXhwRRwFbI+JhYJzmObIXZub2iLgTuBK4u8fHJElqMe3UTWa+0VLkjwJOBP4fsBzYUpptLtsAl0zEy2h9K3A+8C5gQWZub9NHktQnXc/RR8RFwGeBz2bmKM3Uy66yexxYVP4jaI1P7BvaT3ySsbExhoeH932tX79+JscjSZqi6wePZOYDwAMR8emI+BVgB7AQ2EkzH/9yZu6JiIn4hIHStlN8ksHBQUZHR2d6HJKkDqYd0UfEj0RE6xTLszTTMBuBpSV2btmmNR4RRwOnA4/QnLTdHREntOkjSeqTbkb0rwErI+IsYKJw/0fg+8DtEXEazUqcVQCZ+VhEbIqINTSrbq7PzJ0AEbECuC0ingOOBD7V4+ORJE0xbaHPzGdoVtm0c1WHPnd0iD8FrOw2OUnSwfPh4JJ6yoeGzz9eGStJlbPQS1LlLPSSVDkLvSRVzkIvSZWz0EtS5Sz0klQ5C70kVc5CL0mVs9BLUuW8BYKq4SMDpfYc0UtS5Sz0klQ5C70kVc5CL0mVs9BLUuWmXXUTEacAtwJfBk4E/iEzfzsijgPW0jwLdglwc2a+UPrcQPPw70XAg5l5X4mfCVxN89zZIWBVZu7p9UFJkt7UzfLK44A/zszPAETE/42IjTSPEXwoM++JiEuBdcAVEXEOsCwzL46Io4CtEfEwMA5sAC7MzO0RcSdwJXB3H45LklR088zYJ6aEjgD+EVgO3FZim3nzQd+XAFtK3z0RsRU4H/g6sCAzt7f0WYGFXjos+IjBuTOjOfqI+Cnggcz8G5qpl11l1ziwqIzgW+MT+4b2E5ck9VHXhT4ilgHLgP9UQjuAheX1APBymW9vjU/s27Gf+CRjY2MMDw/v+1q/fn23KUqS2ujqFggRsRw4D/g14B0RcTKwEVgKfAs4t2xT/lxd+h0NnA48ArwC7I6IE8r0TWuffQYHBxkdHT2YY5Iktehm1c2PAn8CjAKbgB8C/htwM3B7RJwGnAKsAsjMxyJiU0SsoVl1c31m7izvtQK4LSKeA47kzXl9SVKfdHMy9kngbR12X9Whzx0d4k8BK7tNTmrHm5dJM+MFU5JUOQu9JFXOQi9JlbPQS1LlLPSSVDkLvSRVzkIvSZWz0EtS5Sz0klQ5C70kVa6rm5pJUr94n/r+s9Br3vKeNlJvOHUjSZWz0EtS5Sz0klQ5C70kVc5CL0mVs9BLUuW6eWbsCcCtwHsz8+wSOxZYBzwPLAHWZuY3yr4VwFnAXuCZzPxkiS8GPgI8DSymeZbsqz0+HknSFN2M6H8M+AwQLbFrgb/LzN8BPg7cDRARJ9I8JHxVZn4I+MWIWFL63AV8svT5P8CNPTkCSdJ+TVvoM/PPgF1TwsuBLWX/14D3RsQAcBHwZGZmabcF+EBEHA0sA54o8c3lPSRJfXagV8YOMbn4j5dYp/jxwO6W/wAm4m8xNjbG8PDwvu2RkRFGRkYOME0dCrwCVuqvAy30O4CFLdsDJbYDOHVK/GngRWBBREQp9hPt32JwcJDR0dEDTEuSNNWBFvqNwFLg0Yg4A/hKZo5HxAPANS0FfSnwicx8PSI2AWcDjwPnlveQpLa82VnvdLPq5nzgCuAdEfEbwJ3A7wHryvapwEqAzPx2RKwDPh4Re4Hfz8y/LW/1y8DqiHg/cBJwXc+PRpL0FtMW+sx8GHi4za6rO7TfAGxoE98GfHCG+UmSDpIXTElS5Sz0klQ5HzyiWeMySmluOKKXpMpZ6CWpchZ6Saqcc/TqOefipfnFQi/pkOIVszPn1I0kVc5CL0mVc+pGB8y5eOnQ4IhekirniF7TcuQuHdoc0UtS5RzRS6qCyy47s9BrH6dopDo5dSNJlXNEfxhy5K7DiVM6czCij4gLI+K/R8QtEfGbs/35U61fv36uU+jKgeS5+KaNbb/6ZddT9/ftvXvJPHvLPHunX/VoVkf0EfGDwF3AezLztYi4NyIuyMzPz2YerdavX8/IyMhcfXzXOuU5n0bnr37lfhae+W/mOo1pmWdvHap5zseRfr/q0WxP3SwFnsvM18r2ZmA5MGeFfr7p9MP3nedfmVdFXarV/v6dHarTPZGZs/dhEZcDP5eZP1m2fxF4X2auaGmzi8lTSmPAi31M6/g+v3+vHAp5Hgo5gnn2mnn2zsHkeHJmDrbbMdsj+h3AwpbtgRLbJzMXIknqmdk+GbsFODkijinb5wLOR0hSH83q1A1ARPw48NM0UzKvZ+ZvzWoCknSYmfVCPxci4jhgLfBNYAlwc2a+MKXN2cC1wF8DPww8npn/o+xbDHwEeBpYDFyfma/Odo6l3anAOmBPZv50S/wW4H0tTW/LzM/1Msce5dlV/1nMcwVwFrAXeCYzP1nidwHvbml6TWZ+rYf5XQhcRjN1mVMHPBFxLM337/mS/9rM/Mb+cu61g8xxG7CtNH0+M3++Hzl2k2dp83PAGuDXMvOzM+k7T/J8DPhe2dybmRfM6MMzs/ovmiWdP1teXwr8QZs2/xb4l+X10cDLwPFl+/6WfdcAH52LHMu+nwdGgD+bEr9lvnwvp8mzq/6z9Hd+IvAUbw54ngCW9Pv7CfwgzaDhmLJ9L3DBlDY3AR8qr88AHp0u5/mS4yz/PHaT5z8DlgF/BVwyk77zIc9efD8Pl1sgLKc5PwBvLumcJDPvy8zHW0J7gNcj4miab/4T++s/GzmWPP8Q+H67fRHx6xGxKiJuLNcs9MPB5tlV/x7o5nMuAp7M8i+ptP9Aeb2wfD9vjIhfjYheLlzotMy41b78s/lN4r0RMTBNzr10MDkCnBcRH4qIj0bEv+pDfl3nmZnPZuamA+k7T/IEOKP8LN4SETPOsZpbIETEA8A/abNrNTAE7Crb48CiiDgqM/d0eLtfBdZk5isR8Q5gd8s/rPHyfnOd41R/CmzLzH+MiF8BPgGsnId5Hmz/XubZ2mai3cTf7R8CX83MPRHxMeDDwEdnmmMH+/vc6dp003eucxwHPpyZj5cBx5cj4pLMfHqO8uxH35k62M+6vXw/jwQeiYhdmflIt52rKfSZeVGnfRExsaxzJ82Szpc7FZaI+PfAD2XmrSX0IrAgIqIU+7csCZ3tHDu899dbNr8A3HAgOZb36luevLnE9kD79zLPHcCpLdsDNL9ek5lfbol/AbiR3hX6aZcZ76dNx5x77GByZOK348z8bkQ8RbPCbq7y7EffmTqoz2r5fu6NiEdpZhm6LvSHy9TNRppfnaBlSWdEHBERJ000KhdwDWXmrRFxRkSclpmvA5uAs6f2n4scO4mIO1o2lwDP9DzDxkHl2al/H3ST5wPAj0ZElO2lwP8u7fr5/Wy7zDgijmuZ+tiXf0ScAXwlM8f3l3OPHXCOEXFBRLTeE+FU+vfz2E2eM+o73/KMiHdHROtv5zP+eTycVt3cDjwHnALclJkvRMSZNCfpzoiInwA+TbPqBuDtNCst/qqsullNs4LjJOC67M+qm/3mWNr9BPALNCuDPp2ZHyvx36E54bOD5sTY6iwrIOZZnm37z2GeK4BhmhUs38g3V938T+AF4LvlGK7rZZ7tlhmXKaKXMnNtRCygWdHyHZpCuSYnr7p5S869dqA5lqJ/C/Ak8E7g7zNzTT9y7DLPAH6dZirzi8CGzHygU9/5lmdEvBP4rzS1aYBmsch1mflG1599OBR6STqcHS5TN5J02LLQS1LlLPSSVDkLvSRVzkIvSZWz0EtS5Sz0klQ5C70kVe7/A2tza1Si9HaVAAAAAElFTkSuQmCC
"/>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="training-with-the-optimized-pipeline">Training with the optimized pipeline</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">PiNet_QM9_pipeline</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;/tmp/PiNet_QM9_pipeline&#39;</span><span class="p">,</span>
          <span class="s1">&#39;network&#39;</span><span class="p">:</span> <span class="p">{</span>
              <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;PiNet&#39;</span><span class="p">,</span>
              <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span>
                  <span class="s1">&#39;atom_types&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
              <span class="p">},</span>
          <span class="p">},</span>
          <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="p">{</span>
              <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;potential_model&#39;</span><span class="p">,</span>
              <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span>
                  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="c1"># Relatively large learning rate</span>
                  <span class="s1">&#39;e_scale&#39;</span><span class="p">:</span> <span class="mf">627.5</span><span class="p">,</span> <span class="c1"># Here we scale the model to kcal/mol</span>
                  <span class="s1">&#39;e_dress&#39;</span><span class="p">:</span> <span class="n">dress</span>
              <span class="p">}</span>
          <span class="p">}</span>
         <span class="p">}</span>

<span class="c1"># The logging behavior of estimator can be controlled here</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">log_step_count_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># Preprocessing the datasets</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># If you are pre-processing the dataset in the training script,</span>
<span class="c1"># the preprocessing layer will occupy the namespace of the network</span>
<span class="c1"># resulting unexpected names in the ckpts and errors durning prediction</span>
<span class="c1"># To avoid this, wrap your preprocessing function with a name_scope.</span>
<span class="c1"># This will not be a problem if you save a preprocessed dataset</span>
<span class="k">def</span> <span class="nf">pre_fn</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;PRE&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">network</span> <span class="o">=</span> <span class="n">get_network</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;network&#39;</span><span class="p">])</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensors</span>

<span class="n">train</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">dataset</span><span class="p">()[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">pre_fn</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">dataset</span><span class="p">()[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sparse_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>

<span class="c1"># Running specs</span>
<span class="n">train_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">TrainSpec</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="mf">1e4</span><span class="p">)</span>
<span class="n">eval_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EvalSpec</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">test</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNet_QM9_pipeline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_spec</span><span class="p">,</span> <span class="n">eval_spec</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
INFO:tensorflow:Calling model_fn.
12112 trainable vaiabless, training with float32 precision.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
INFO:tensorflow:Saving checkpoints for 0 into /tmp/PiNet_QM9_pipeline/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
INFO:tensorflow:loss = 1608.7036, step = 0
INFO:tensorflow:global_step/sec: 11.2424
INFO:tensorflow:loss = 309.28052, step = 500 (44.477 sec)
INFO:tensorflow:global_step/sec: 11.6739
INFO:tensorflow:loss = 147.40509, step = 1000 (42.830 sec)
INFO:tensorflow:global_step/sec: 25.8236
INFO:tensorflow:loss = 115.164055, step = 1500 (19.362 sec)
INFO:tensorflow:global_step/sec: 26.4694
INFO:tensorflow:loss = 126.90699, step = 2000 (18.894 sec)
INFO:tensorflow:global_step/sec: 26.1443
INFO:tensorflow:loss = 103.33997, step = 2500 (19.120 sec)
INFO:tensorflow:global_step/sec: 26.1268
INFO:tensorflow:loss = 96.97985, step = 3000 (19.137 sec)
INFO:tensorflow:global_step/sec: 25.9872
INFO:tensorflow:loss = 107.959435, step = 3500 (19.241 sec)
INFO:tensorflow:global_step/sec: 26.0982
INFO:tensorflow:loss = 83.18972, step = 4000 (19.158 sec)
INFO:tensorflow:global_step/sec: 26.2075
INFO:tensorflow:loss = 70.3028, step = 4500 (19.080 sec)
INFO:tensorflow:global_step/sec: 25.9199
INFO:tensorflow:loss = 84.25394, step = 5000 (19.289 sec)
INFO:tensorflow:global_step/sec: 26.4121
INFO:tensorflow:loss = 129.86829, step = 5500 (18.930 sec)
INFO:tensorflow:global_step/sec: 25.8288
INFO:tensorflow:loss = 132.20454, step = 6000 (19.359 sec)
INFO:tensorflow:global_step/sec: 26.261
INFO:tensorflow:loss = 69.64721, step = 6500 (19.038 sec)
INFO:tensorflow:global_step/sec: 26.1977
INFO:tensorflow:loss = 62.85822, step = 7000 (19.086 sec)
INFO:tensorflow:global_step/sec: 26.0748
INFO:tensorflow:loss = 69.52461, step = 7500 (19.176 sec)
INFO:tensorflow:global_step/sec: 26.3489
INFO:tensorflow:loss = 93.84022, step = 8000 (18.975 sec)
INFO:tensorflow:global_step/sec: 25.3495
INFO:tensorflow:loss = 97.3127, step = 8500 (19.724 sec)
INFO:tensorflow:global_step/sec: 25.7534
INFO:tensorflow:loss = 43.729958, step = 9000 (19.416 sec)
INFO:tensorflow:global_step/sec: 26.3466
INFO:tensorflow:loss = 41.565964, step = 9500 (18.977 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...
INFO:tensorflow:Saving checkpoints for 10000 into /tmp/PiNet_QM9_pipeline/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2021-05-31T15:01:59
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/PiNet_QM9_pipeline/model.ckpt-10000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Inference Time : 10.84179s
INFO:tensorflow:Finished evaluation at 2021-05-31-15:02:10
INFO:tensorflow:Saving dict for global step 10000: METRICS/E_LOSS = 71.01845, METRICS/E_MAE = 5.8880224, METRICS/E_RMSE = 8.427245, global_step = 10000, loss = 71.01845
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/PiNet_QM9_pipeline/model.ckpt-10000
INFO:tensorflow:Loss for final step: 82.67876.
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>({'METRICS/E_LOSS': 71.01845,
  'METRICS/E_MAE': 5.8880224,
  'METRICS/E_RMSE': 8.427245,
  'loss': 71.01845,
  'global_step': 10000},
 [])</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="monitoring">Monitoring</h2>
<p>It's recommended to monitor the training with Tensorboard instead of the stdout here.<br />
Try <code>tensorboard --logdir /tmp</code></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="parallelization-with-tfestimator">Parallelization with tf.Estimator</h2>
<p>The estimator api makes it extremely easy to train on multiple GPUs.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># suppose you have two cards</span>
<span class="n">distribution</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">([</span><span class="s2">&quot;GPU:0&quot;</span><span class="p">,</span> <span class="s2">&quot;GPU:1&quot;</span><span class="p">])</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">train_distribute</span><span class="o">=</span><span class="n">distribution</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="conclusions">Conclusions</h2>
<p>Congratulations! You can now train atomic neural networks with 
state-of-the-art accuracy and speed.</p>
<p>But there's more. With PiNN, the components of ANNs are modulized.
Read the following notebooks to see how you can build your own ANN. </p>
</div>
</div>
</div>
    </div>

  </div>

  <div class="page">
    <div class="page-prev">
      
      <a href="../Quick_tour/" title="Quick Start"><span>«</span> Previous</a>
      
    </div>
    <div class="page-next">
      
      <a href="../Customizing_dataset/" title="Custom Data" />Next <span>»</span></a>
      
    </div>
  </div>

  <div class="footer">
    Built with <a href="https://www.mkdocs.org">mkdocs</a> and the <a href="https://github.com/yqshao/mkdocs-flux-theme">flux</a> theme.
  </div>
</body>
</html>